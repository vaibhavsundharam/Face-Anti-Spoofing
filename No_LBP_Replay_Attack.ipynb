{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "No LBP Replay Attack.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "65UrbbGICLyC"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaibhavsundharam/Face-Anti-Spoofing/blob/master/No_LBP_Replay_Attack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Gw7phDEoKIY",
        "colab_type": "text"
      },
      "source": [
        "# General Initializations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2aujqeJAcst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import sys\n",
        "import os\n",
        "from __future__ import print_function, division\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from skimage.transform import resize\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import PIL\n",
        "from google.colab.patches import cv2_imshow\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.ion()   # interactive mode\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSRYatULQ-MS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2ec78d6f-10a9-45ca-9412-dd125e3382ce"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx-LxXr1RLrk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ebaa1b3c-7a56-4875-d54c-d82ff930921f"
      },
      "source": [
        "# Set device on GPU if available, else CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8Vah2PwK4EZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8deb2e35-78cb-4dee-9e75-70a154ccda84"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b6NDAJhKvjS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8a5c9af7-9927-4f65-dc47-1a1e22015b39"
      },
      "source": [
        "prefix = '/content/gdrive/My Drive/'\n",
        "# modify \"customized_path_to_your_project\" \n",
        "customized_path_to_your_project = '/content/gdrive/My Drive/Machine Learning/Face Anti-spoofing/' # enter the main directory (change location as required)\n",
        "sys_path = os.path.join(prefix, customized_path_to_your_project)\n",
        "sys.path.append(sys_path)\n",
        "print(f\"sys_path: {sys_path}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sys_path: /content/gdrive/My Drive/Machine Learning/Face Anti-spoofing/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaY0BNzELi7L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "193c2f40-be6b-462a-966a-45652e2e3416"
      },
      "source": [
        "# reading the text file with real and fake faces\n",
        "data_directory=sys_path+\"Data/Replay Attack\"\n",
        "print(f\"Data directory location:{data_directory}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data directory location:/content/gdrive/My Drive/Machine Learning/Face Anti-spoofing/Data/Replay Attack\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsH-ijYHoTow",
        "colab_type": "text"
      },
      "source": [
        "#Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPcjDrVXOVhi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5264cdc4-7b1a-4fba-dcfd-182d72625719"
      },
      "source": [
        "# combining real and fake faces file for training and dev\n",
        "\n",
        "train_real_txt_file=data_directory+\"/train_real.txt\"  \n",
        "train_attack_txt_file=data_directory+\"/train_attack.txt\"\n",
        "\n",
        "train_real_images_loc=data_directory+\"/train_real/\" \n",
        "train_attack_images_loc=data_directory+\"/train_attack/\"\n",
        "\n",
        "train_data=[(train_real_txt_file, train_real_images_loc, 1), (train_attack_txt_file, train_attack_images_loc, 0 )] # encoding the class\n",
        "\n",
        "#train_img_list=list() # list containing the location of images \n",
        "\n",
        "with open(\"train_combined.txt\", \"w\") as out:\n",
        "  for a,b,c in train_data:\n",
        "    with open(a, \"r\") as file:\n",
        "      for line in file:        \n",
        "        line=line.rstrip()\n",
        "        out.write(b + \"/\" +line + \"/\" + str(c) + \"\\n\")\n",
        "        \n",
        "read_file_train=pd.read_csv (r'/content/train_combined.txt', header = None)\n",
        "read_file_train.columns = [\"image\"]\n",
        "read_file_train.to_csv (r\"train_combined.csv\", index=None)       \n",
        "print(f\"Total number of examples for training: {len(read_file_train)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of examples for training: 2950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOG6cZkIiRTI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1cfab0e4-ff1d-45f4-d9d6-f728d130f678"
      },
      "source": [
        "# combining real and fake faces file for dev and converting it to a csv \n",
        "\n",
        "dev_real_txt_file=data_directory+\"/dev_real.txt\"\n",
        "dev_attack_txt_file=data_directory+\"/dev_attack.txt\"\n",
        "\n",
        "dev_real_images_loc=data_directory+\"/dev_real/\" \n",
        "dev_attack_images_loc=data_directory+\"/dev_attack/\"\n",
        "\n",
        "dev_data=[(dev_real_txt_file, dev_real_images_loc, 1),(dev_attack_txt_file, dev_attack_images_loc, 0)]\n",
        "\n",
        "#dev_img_list=list() # list containing the location of images \n",
        "\n",
        "with open(\"dev_combined.txt\", \"w\") as out:\n",
        "  for a,b,c in dev_data:\n",
        "    with open(a, \"r\") as file:\n",
        "      for line in file:        \n",
        "        line=line.rstrip()\n",
        "        out.write(b + \"/\" +line + \"/\" + str(c) + \"\\n\")\n",
        "        \n",
        "read_file_dev = pd.read_csv (r'/content/dev_combined.txt', header = None)\n",
        "read_file_dev.columns = [\"image\"]\n",
        "read_file_dev.to_csv (r\"dev_combined.csv\", index=None)\n",
        "\n",
        "print(f\"Total number of examples for dev set: {len(read_file_dev)}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of examples for dev set: 2937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGrY6QyqBFFt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a47a1f02-1696-4f7b-9804-eb90cf0a5910"
      },
      "source": [
        "# combining real and fake faces file for testing and converting it to a csv \n",
        "\n",
        "test_real_txt_file=data_directory+\"/test_real.txt\"\n",
        "test_attack_txt_file=data_directory+\"/test_attack.txt\"\n",
        "\n",
        "test_real_images_loc=data_directory+\"/test_real/\" \n",
        "test_attack_images_loc=data_directory+\"/test_attack/\"\n",
        "\n",
        "test_data=[(test_real_txt_file, test_real_images_loc, 1),(test_attack_txt_file, test_attack_images_loc, 0)]\n",
        "\n",
        "#test_img_list=list() # list containing the location of images \n",
        "\n",
        "with open(\"test_combined.txt\", \"w\") as out:\n",
        "  for a,b,c in test_data:\n",
        "    with open(a, \"r\") as file:\n",
        "      for line in file:        \n",
        "        line=line.rstrip()\n",
        "        out.write(b + \"/\" +line + \"/\" + str(c) + \"\\n\")\n",
        "        \n",
        "read_file_test = pd.read_csv (r'/content/test_combined.txt', header = None)\n",
        "read_file_test.columns = [\"image\"]\n",
        "read_file_test.to_csv (r\"test_combined.csv\", index=None)\n",
        "\n",
        "print(f\"Total number of examples for test set: {len(read_file_test)}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of examples for test set: 3888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTTOsLoooX0Q",
        "colab_type": "text"
      },
      "source": [
        "# Data loaders and data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5O8MAqSc5xI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# custom class to explore dataset\n",
        "class face_dataset(Dataset):\n",
        "  def __init__(self, data_split_csv_loc, transform=None): \n",
        "    self.data_split_csv_loc=pd.read_csv(data_split_csv_loc)    \n",
        "    self.transform=transform    \n",
        "    \n",
        "\n",
        "  def __len__(self):  # returns the length of the data set\n",
        "     return len(self.data_split_csv_loc)\n",
        "\n",
        "  def __getitem__(self, idx):    \n",
        "    img_loc=self.data_split_csv_loc.iloc[idx,0][:-2]           \n",
        "    img_class=int(self.data_split_csv_loc.iloc[idx,0][-1])\n",
        "    img_transform=self.transform(Image.open(img_loc))    \n",
        "    \n",
        "    return  img_transform,   img_class  #---> returned values are a touple and image class "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKpuWr5fWaDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class normalize_HPF():\n",
        "  def __init__(self):\n",
        "    self.kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
        "\n",
        "  def __call__(self, sample):\n",
        "    sample = np.array(sample)\n",
        "    image=cv2.normalize( sample, None, 0, 255, cv2.NORM_MINMAX) # normalization\n",
        "    image=cv2.filter2D(image, -1, self.kernel) # high pass filtering\n",
        "\n",
        "    return image\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SoyfXZB7RG3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "48e9a0d2-e2cd-4165-d1bd-ee5394ce88c9"
      },
      "source": [
        "# Here we create two seperate instances of the face_dataset class. One will hold the data set for training and the other will hold data for dev\n",
        "\n",
        "train_dataset=face_dataset(data_split_csv_loc=\"/content/train_combined.csv\", transform=transforms.Compose([transforms.Resize((150, 150)),\n",
        "                                                                                                          transforms.RandomHorizontalFlip(),\n",
        "                                                                                                          normalize_HPF(),\n",
        "                                                                                                          transforms.ToTensor()]))\n",
        "dev_dataset=face_dataset(data_split_csv_loc=\"/content/dev_combined.csv\", transform= transforms.Compose([transforms.Resize((150 , 150)), \n",
        "                                                                                                      normalize_HPF(),\n",
        "                                                                                                      transforms.ToTensor()]))\n",
        "test_dataset=face_dataset(data_split_csv_loc=\"/content/test_combined.csv\", transform= transforms.Compose([transforms.Resize((150, 150)), \n",
        "                                                                                                          normalize_HPF(),\n",
        "                                                                                                          transforms.ToTensor()]))\n",
        "\n",
        "\n",
        "len_train_dataset, len_dev_dataset, len_test_dataset, =len(train_dataset), len(dev_dataset), len(test_dataset) \n",
        "print(f\"Total number of elements in training dataset: {len_train_dataset}\")\n",
        "print(f\"Total number of elements in dev dataset: {len_dev_dataset}\")\n",
        "print(f\"Total number of elements in test dataset: {len_test_dataset}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of elements in training dataset: 2950\n",
            "Total number of elements in dev dataset: 2937\n",
            "Total number of elements in test dataset: 3888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4UYkRBYne_I",
        "colab_type": "text"
      },
      "source": [
        "#Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPykJGliY7TW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for plotting LBP \n",
        "\n",
        "def plot(batch):   \n",
        "  fig, axs = plt.subplots(batch.shape[0], batch.shape[1]+1, figsize=(25,25))  \n",
        " \n",
        "  \n",
        "  \"\"\"plotting the images on which lbp is calculated \"\"\"\n",
        "  for img in range(touple[1].shape[0]):\n",
        "    \n",
        "    axs[img, 0 ].imshow(touple[1][img], cmap = \"gray\")\n",
        "\n",
        "  \"\"\"plotting the LBP of the image \"\"\"     \n",
        "  for example in range(touple[0].shape[0]):\n",
        "    \n",
        "    for image in range(touple[0].shape[1]):\n",
        "      \n",
        "      axs[example, image+1].imshow(touple[0][example][image], cmap= \"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FHpZdO6xQSK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8a91172c-e876-46d5-f81c-cc249bf4b12d"
      },
      "source": [
        "plot_loader=DataLoader(train_dataset, batch_size=8, shuffle=False, num_workers=8) \n",
        "\n",
        "for batch, label  in plot_loader:  # getting one batch for visualizing data  \n",
        "  print(batch.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 3, 150, 150])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxquidZWp5DF",
        "colab_type": "text"
      },
      "source": [
        "#Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_x3Xmh9MxAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get true positives, true negatives,  false positives and false negatives\n",
        "\n",
        "def confusion_matrix(ys, y_preds):\n",
        "  ys=ys.detach()\n",
        "  ys=ys.to(\"cpu\")\n",
        "  y_preds=y_preds.detach()\n",
        "  y_preds=y_preds.to(\"cpu\")\n",
        "\n",
        "  ys=np.asarray(ys)\n",
        "  y_preds=np.asarray(y_preds)  \n",
        "\n",
        "  tp=np.sum((y_preds == 1) & (ys == 1))\n",
        "  tn=np.sum((y_preds == 0) & (ys == 0))\n",
        "  fp=np.sum((y_preds == 1) & (ys == 0))\n",
        "  fn=np.sum((y_preds == 0) & (ys == 1))\n",
        "\n",
        "  print(f\"tp:{tp}, tn: {tn}, fp:{fp}, fn: {fn}\") \n",
        "\n",
        "  return tp, tn, fp, fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrad6d71BMIP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a6eb3eb5-3067-48f0-e0f9-036f43aad992"
      },
      "source": [
        "# def confusion matrix test\n",
        "\n",
        "a=torch.Tensor([1,1,1,0,0,0])\n",
        "b=torch.Tensor([0,1,0,1,0,1])\n",
        "\n",
        "TP, TN, FP, FN=confusion_matrix(a, b)\n",
        "print(f\"TP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}\")\n",
        "print(\"Answer:TP: 1, TN: 1, FP: 2, FN: 2\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tp:1, tn: 1, fp:2, fn: 2\n",
            "TP: 1, TN: 1, FP: 2, FN: 2\n",
            "Answer:TP: 1, TN: 1, FP: 2, FN: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7dHSsBCQVph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# HTER claculation for test and validation\n",
        "def HTER(model, loss_criterion, loader):\n",
        "  Ys=list()\n",
        "  Y_preds=list()\n",
        "  Loss_total=0    \n",
        "  total_step=len(loader)\n",
        "  \n",
        "  for touple, label in loader:\n",
        "    batch=touple\n",
        "    batch=batch.to(device=device, dtype=torch.float)\n",
        "    label=label.to(device=device, dtype=torch.long)\n",
        "    Ys.append(label) \n",
        "    Y_pred=model(batch)       \n",
        "    Y_preds.append(torch.argmax(Y_pred, dim=1))    \n",
        "    Loss=loss_criterion(Y_pred,label)    \n",
        "    Loss_total += Loss.item() \n",
        "    \n",
        "    \n",
        "  Y= torch.cat(Ys, dim=0)\n",
        "  Y_pred=torch.cat(Y_preds, dim=0)\n",
        "  tp, tn, fp, fn =confusion_matrix(Y, Y_pred)\n",
        "  hter=1-(0.5*((tp/(tp+fn))+(tn/(tn+fp))))\n",
        "  \n",
        "  return (hter*100, Loss_total/total_step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_-ezXy2Y9TN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# solver function for Neural Network\n",
        "\n",
        "def Solver_NN(model, train_loader, dev_loader, optim, criterion, device,  scheduler, print_every=10, epoch=51, lr=1e-1):\n",
        "  print(\"Solver Initiated\")  \n",
        "  model=model.to(device) # sending model to GPU\n",
        "  print(\"Model successfully sent to the GPU\\n\")\n",
        "\n",
        "  print_every=print_every\n",
        "  total_step = len(train_loader)\n",
        "  counter=0\n",
        "\n",
        "  for e in range(epoch):\n",
        "    running_loss = 0.0    \n",
        "    epoch_loss=0.0\n",
        "    for i, (x,y) in enumerate(train_loader):\n",
        "      optim.zero_grad()\n",
        "\n",
        "      X=x      \n",
        "      #print(X.shape)\n",
        "      X=X.to(device=device, dtype=torch.float)\n",
        "      y=y.to(device=device, dtype=torch.long)\n",
        "     \n",
        "      #forward pass########\n",
        "      y_pred=model(X)                  \n",
        "      loss=criterion(y_pred, y)          \n",
        "      ####################\n",
        "      \n",
        "      # backward pass#######     \n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "      ####################      \n",
        "      running_loss += loss.item()\n",
        "      epoch_loss+=running_loss\n",
        "      if (i+1) % print_every == 0:       # print every 10\n",
        "        print (\"Epoch [{}/{}], Step [{}/{}] Loss: {}\".format(counter+1, epoch, i+1, total_step, running_loss/print_every))\n",
        "        running_loss = 0.0\n",
        "    counter+=1     \n",
        "\n",
        "    with torch.no_grad():            \n",
        "      train_hter, train_loss=HTER(model=model, loss_criterion=criterion, loader=train_loader)    \n",
        "      dev_hter, dev_loss=HTER(model=model, loss_criterion=criterion, loader=dev_loader)           \n",
        "      print(f\"Train loss in epoch {e+1} is {(train_loss)} and Train HTER in epoch {e+1}: {train_hter}\") \n",
        "      print(f\"Dev loss in epoch {e+1} is {(dev_loss)} and Dev HTER in epoch {e+1}: {dev_hter}\")  \n",
        "      scheduler.step(dev_loss)    \n",
        "    torch.save(model.state_dict(), sys_path + 'Codes/Replay Attack/weights_replay_attack_1FPS/weights/Resnet_Replay_attack_No_LBP_'+ str(e+1) + \"_\" + str(np.floor(dev_hter))+'.pkl') \n",
        "    print(\"Model saved successfully!\\n\")\n",
        "    \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI8pSbnyG6eT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##DO NOT CHANGE##\n",
        "class Resnet(nn.Module):\n",
        "  def __init__(self,  model):\n",
        "    super().__init__()    \n",
        "    self.cnn=nn.Sequential(*(list(model.children())[0:5]), nn.AdaptiveAvgPool2d(output_size=(1, 1)), nn.Flatten())    \n",
        "    self.fc=nn.Sequential(nn.Linear(256, 128), nn.Dropout(p=0.5), nn.Linear(128, 2))     \n",
        "\n",
        "  def forward(self, x):  \n",
        "\n",
        "    x=self.cnn(x)\n",
        "    #print(f\"2: {x.shape}\")\n",
        "\n",
        "    x=self.fc(x)\n",
        "    #print(f\"3 {x.shape}\")\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAjKzmcubHWi",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q85boa7dmMz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "b6867e47-a1a4-49a8-e15a-352de9e5daa2"
      },
      "source": [
        "resnet=torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=False)\n",
        "model= Resnet(resnet )\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Resnet(\n",
            "  (cnn): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (5): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (6): Flatten()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (1): Dropout(p=0.5, inplace=False)\n",
            "    (2): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elFof5WAc-zp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#criterion and optimizer\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "lr=0.001\n",
        "criterion=nn.CrossEntropyLoss(reduction='mean') # loss criterion \n",
        "optim=torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1.5) # optimizer \n",
        "scheduler =  ReduceLROnPlateau(optim, mode='min', factor=0.1, patience= 2, verbose=True, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9tOnhb9diF3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4dd82d48-860e-4c83-e2ca-47f0543f19e6"
      },
      "source": [
        "# GPU Access and model parameters\n",
        "use_cuda = True\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  print(\"Running on Cuda\")\n",
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "print(\"Learnable parameters:\",params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on Cuda\n",
            "Learnable parameters: 258498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-Xa4275A-iJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading training and validation data for the neural network\n",
        "train_loader=DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=8) \n",
        "dev_loader=DataLoader(dev_dataset, batch_size=256, shuffle=True, num_workers=8) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkIXJFPpdrAN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4894918a-2acf-4b39-ad67-977f69a0da47"
      },
      "source": [
        "model=Solver_NN(model, train_loader, dev_loader, optim,criterion, device, scheduler, print_every=5, epoch=101, lr=lr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Solver Initiated\n",
            "Model successfully sent to the GPU\n",
            "\n",
            "Epoch [1/101], Step [5/12] Loss: 0.5450669646263122\n",
            "Epoch [1/101], Step [10/12] Loss: 0.4730373203754425\n",
            "tp:100, tn: 2229, fp:4, fn: 617\n",
            "tp:82, tn: 2211, fp:6, fn: 638\n",
            "Train loss in epoch 1 is 0.4730897918343544 and Train HTER in epoch 1: 43.11606490945692\n",
            "Dev loss in epoch 1 is 0.4825307254989942 and Dev HTER in epoch 1: 44.44087355284919\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [2/101], Step [5/12] Loss: 0.4900302529335022\n",
            "Epoch [2/101], Step [10/12] Loss: 0.4462247252464294\n",
            "tp:53, tn: 2233, fp:0, fn: 664\n",
            "tp:34, tn: 2217, fp:0, fn: 686\n",
            "Train loss in epoch 2 is 0.45138083895047504 and Train HTER in epoch 2: 46.30404463040446\n",
            "Dev loss in epoch 2 is 0.4628371198972066 and Dev HTER in epoch 2: 47.638888888888886\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [3/101], Step [5/12] Loss: 0.44024282693862915\n",
            "Epoch [3/101], Step [10/12] Loss: 0.47733322978019715\n",
            "tp:119, tn: 2233, fp:0, fn: 598\n",
            "tp:91, tn: 2217, fp:0, fn: 629\n",
            "Train loss in epoch 3 is 0.45843131343523663 and Train HTER in epoch 3: 41.70153417015342\n",
            "Dev loss in epoch 3 is 0.4689044306675593 and Dev HTER in epoch 3: 43.68055555555556\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [4/101], Step [5/12] Loss: 0.4514941334724426\n",
            "Epoch [4/101], Step [10/12] Loss: 0.45515976548194886\n",
            "tp:20, tn: 2233, fp:0, fn: 697\n",
            "tp:14, tn: 2217, fp:0, fn: 706\n",
            "Train loss in epoch 4 is 0.4599117611845334 and Train HTER in epoch 4: 48.60529986052998\n",
            "Dev loss in epoch 4 is 0.46784426271915436 and Dev HTER in epoch 4: 49.02777777777778\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [5/101], Step [5/12] Loss: 0.45531917214393614\n",
            "Epoch [5/101], Step [10/12] Loss: 0.4584304094314575\n",
            "tp:1, tn: 2233, fp:0, fn: 716\n",
            "tp:0, tn: 2217, fp:0, fn: 720\n",
            "Train loss in epoch 5 is 0.4550132006406784 and Train HTER in epoch 5: 49.9302649930265\n",
            "Dev loss in epoch 5 is 0.46032991260290146 and Dev HTER in epoch 5: 50.0\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [6/101], Step [5/12] Loss: 0.44683985114097596\n",
            "Epoch [6/101], Step [10/12] Loss: 0.4571001648902893\n",
            "tp:0, tn: 2233, fp:0, fn: 717\n",
            "tp:0, tn: 2217, fp:0, fn: 720\n",
            "Train loss in epoch 6 is 0.4459080720941226 and Train HTER in epoch 6: 50.0\n",
            "Dev loss in epoch 6 is 0.4564105148116748 and Dev HTER in epoch 6: 50.0\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [7/101], Step [5/12] Loss: 0.4580187380313873\n",
            "Epoch [7/101], Step [10/12] Loss: 0.43096408247947693\n",
            "tp:0, tn: 2233, fp:0, fn: 717\n",
            "tp:0, tn: 2217, fp:0, fn: 720\n",
            "Train loss in epoch 7 is 0.4280868818362554 and Train HTER in epoch 7: 50.0\n",
            "Dev loss in epoch 7 is 0.4396730462710063 and Dev HTER in epoch 7: 50.0\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [8/101], Step [5/12] Loss: 0.4319160938262939\n",
            "Epoch [8/101], Step [10/12] Loss: 0.42805410623550416\n",
            "tp:100, tn: 2233, fp:0, fn: 617\n",
            "tp:64, tn: 2217, fp:0, fn: 656\n",
            "Train loss in epoch 8 is 0.41917124887307483 and Train HTER in epoch 8: 43.02649930264993\n",
            "Dev loss in epoch 8 is 0.42760127286116284 and Dev HTER in epoch 8: 45.55555555555556\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [9/101], Step [5/12] Loss: 0.43157681822776794\n",
            "Epoch [9/101], Step [10/12] Loss: 0.39626944065093994\n",
            "tp:73, tn: 2233, fp:0, fn: 644\n",
            "tp:28, tn: 2217, fp:0, fn: 692\n",
            "Train loss in epoch 9 is 0.39440080771843594 and Train HTER in epoch 9: 44.909344490934444\n",
            "Dev loss in epoch 9 is 0.40673695504665375 and Dev HTER in epoch 9: 48.05555555555555\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [10/101], Step [5/12] Loss: 0.4008323073387146\n",
            "Epoch [10/101], Step [10/12] Loss: 0.3763034105300903\n",
            "tp:198, tn: 2233, fp:0, fn: 519\n",
            "tp:134, tn: 2217, fp:0, fn: 586\n",
            "Train loss in epoch 10 is 0.36675379425287247 and Train HTER in epoch 10: 36.19246861924687\n",
            "Dev loss in epoch 10 is 0.38091474523146945 and Dev HTER in epoch 10: 40.69444444444444\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [11/101], Step [5/12] Loss: 0.36132424473762514\n",
            "Epoch [11/101], Step [10/12] Loss: 0.35648191571235655\n",
            "tp:289, tn: 2233, fp:0, fn: 428\n",
            "tp:224, tn: 2217, fp:0, fn: 496\n",
            "Train loss in epoch 11 is 0.3392977739373843 and Train HTER in epoch 11: 29.846582984658298\n",
            "Dev loss in epoch 11 is 0.3542909423510234 and Dev HTER in epoch 11: 34.44444444444444\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [12/101], Step [5/12] Loss: 0.34253995418548583\n",
            "Epoch [12/101], Step [10/12] Loss: 0.3176323473453522\n",
            "tp:427, tn: 2228, fp:5, fn: 290\n",
            "tp:368, tn: 2215, fp:2, fn: 352\n",
            "Train loss in epoch 12 is 0.31513166427612305 and Train HTER in epoch 12: 20.33510903082394\n",
            "Dev loss in epoch 12 is 0.32497576872507733 and Dev HTER in epoch 12: 24.489550443542328\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [13/101], Step [5/12] Loss: 0.31406110525131226\n",
            "Epoch [13/101], Step [10/12] Loss: 0.29836374521255493\n",
            "tp:421, tn: 2230, fp:3, fn: 296\n",
            "tp:417, tn: 2217, fp:0, fn: 303\n",
            "Train loss in epoch 13 is 0.29597196479638416 and Train HTER in epoch 13: 20.70873626926144\n",
            "Dev loss in epoch 13 is 0.3017745465040207 and Dev HTER in epoch 13: 21.04166666666667\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [14/101], Step [5/12] Loss: 0.2690915882587433\n",
            "Epoch [14/101], Step [10/12] Loss: 0.2771876633167267\n",
            "tp:545, tn: 2223, fp:10, fn: 172\n",
            "tp:536, tn: 2208, fp:9, fn: 184\n",
            "Train loss in epoch 14 is 0.26130978142221767 and Train HTER in epoch 14: 12.218335216459586\n",
            "Dev loss in epoch 14 is 0.27359430367747944 and Dev HTER in epoch 14: 12.980754773718239\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [15/101], Step [5/12] Loss: 0.27068609595298765\n",
            "Epoch [15/101], Step [10/12] Loss: 0.2729369968175888\n",
            "tp:480, tn: 2233, fp:0, fn: 237\n",
            "tp:425, tn: 2215, fp:2, fn: 295\n",
            "Train loss in epoch 15 is 0.2675760090351105 and Train HTER in epoch 15: 16.527196652719667\n",
            "Dev loss in epoch 15 is 0.2845239465435346 and Dev HTER in epoch 15: 20.53121711020899\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [16/101], Step [5/12] Loss: 0.27329724431037905\n",
            "Epoch [16/101], Step [10/12] Loss: 0.27347172796726227\n",
            "tp:540, tn: 2231, fp:2, fn: 177\n",
            "tp:504, tn: 2210, fp:7, fn: 216\n",
            "Train loss in epoch 16 is 0.2566542662680149 and Train HTER in epoch 16: 12.387879037713123\n",
            "Dev loss in epoch 16 is 0.2724904865026474 and Dev HTER in epoch 16: 15.157870996842583\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [17/101], Step [5/12] Loss: 0.2622324705123901\n",
            "Epoch [17/101], Step [10/12] Loss: 0.25856430530548097\n",
            "tp:608, tn: 2223, fp:10, fn: 109\n",
            "tp:588, tn: 2196, fp:21, fn: 132\n",
            "Train loss in epoch 17 is 0.2529530388613542 and Train HTER in epoch 17: 7.8250297771290445\n",
            "Dev loss in epoch 17 is 0.2561063865820567 and Dev HTER in epoch 17: 9.640279657194405\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [18/101], Step [5/12] Loss: 0.25131564438343046\n",
            "Epoch [18/101], Step [10/12] Loss: 0.26733786165714263\n",
            "tp:520, tn: 2232, fp:1, fn: 197\n",
            "tp:516, tn: 2212, fp:5, fn: 204\n",
            "Train loss in epoch 18 is 0.2590216596921285 and Train HTER in epoch 18: 13.76018777548138\n",
            "Dev loss in epoch 18 is 0.27600296835104626 and Dev HTER in epoch 18: 14.27943166441137\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [19/101], Step [5/12] Loss: 0.26248099505901334\n",
            "Epoch [19/101], Step [10/12] Loss: 0.24405957758426666\n",
            "tp:583, tn: 2214, fp:19, fn: 134\n",
            "tp:563, tn: 2187, fp:30, fn: 157\n",
            "Train loss in epoch 19 is 0.24642391999562582 and Train HTER in epoch 19: 9.769927566782277\n",
            "Dev loss in epoch 19 is 0.266139704734087 and Dev HTER in epoch 19: 11.579367764245973\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [20/101], Step [5/12] Loss: 0.23340096771717073\n",
            "Epoch [20/101], Step [10/12] Loss: 0.28312000930309295\n",
            "tp:525, tn: 2227, fp:6, fn: 192\n",
            "tp:469, tn: 2207, fp:10, fn: 251\n",
            "Train loss in epoch 20 is 0.2753945589065552 and Train HTER in epoch 20: 13.523469749122619\n",
            "Dev loss in epoch 20 is 0.2969009007016818 and Dev HTER in epoch 20: 17.656085551044953\n",
            "Epoch    20: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [21/101], Step [5/12] Loss: 0.2665758430957794\n",
            "Epoch [21/101], Step [10/12] Loss: 0.26730726957321166\n",
            "tp:544, tn: 2226, fp:7, fn: 173\n",
            "tp:515, tn: 2206, fp:11, fn: 205\n",
            "Train loss in epoch 21 is 0.24757316708564758 and Train HTER in epoch 21: 12.220896018327853\n",
            "Dev loss in epoch 21 is 0.2654542165497939 and Dev HTER in epoch 21: 14.48419410614945\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [22/101], Step [5/12] Loss: 0.2438950389623642\n",
            "Epoch [22/101], Step [10/12] Loss: 0.22941136956214905\n",
            "tp:569, tn: 2228, fp:5, fn: 148\n",
            "tp:529, tn: 2211, fp:6, fn: 191\n",
            "Train loss in epoch 22 is 0.22489039599895477 and Train HTER in epoch 22: 10.432738040586841\n",
            "Dev loss in epoch 22 is 0.2402575947344303 and Dev HTER in epoch 22: 13.399206886182524\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [23/101], Step [5/12] Loss: 0.22108897268772126\n",
            "Epoch [23/101], Step [10/12] Loss: 0.20919443368911744\n",
            "tp:606, tn: 2226, fp:7, fn: 111\n",
            "tp:591, tn: 2211, fp:6, fn: 129\n",
            "Train loss in epoch 23 is 0.19976363703608513 and Train HTER in epoch 23: 7.897325585970805\n",
            "Dev loss in epoch 23 is 0.21611259505152702 and Dev HTER in epoch 23: 9.093651330626972\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [24/101], Step [5/12] Loss: 0.19580184817314147\n",
            "Epoch [24/101], Step [10/12] Loss: 0.19055498242378235\n",
            "tp:658, tn: 2227, fp:6, fn: 59\n",
            "tp:629, tn: 2208, fp:9, fn: 91\n",
            "Train loss in epoch 24 is 0.185894296814998 and Train HTER in epoch 24: 4.248713821647021\n",
            "Dev loss in epoch 24 is 0.20691462233662605 and Dev HTER in epoch 24: 6.522421440384907\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [25/101], Step [5/12] Loss: 0.1965044468641281\n",
            "Epoch [25/101], Step [10/12] Loss: 0.17772697806358337\n",
            "tp:656, tn: 2222, fp:11, fn: 61\n",
            "tp:638, tn: 2209, fp:8, fn: 82\n",
            "Train loss in epoch 25 is 0.17731942857305208 and Train HTER in epoch 25: 4.500140844102751\n",
            "Dev loss in epoch 25 is 0.1878489851951599 and Dev HTER in epoch 25: 5.874868440835968\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [26/101], Step [5/12] Loss: 0.17613992989063262\n",
            "Epoch [26/101], Step [10/12] Loss: 0.16960513591766357\n",
            "tp:646, tn: 2230, fp:3, fn: 71\n",
            "tp:646, tn: 2212, fp:5, fn: 74\n",
            "Train loss in epoch 26 is 0.17117694144447645 and Train HTER in epoch 26: 5.018359700223796\n",
            "Dev loss in epoch 26 is 0.18668578565120697 and Dev HTER in epoch 26: 5.251653886633589\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [27/101], Step [5/12] Loss: 0.17297154366970063\n",
            "Epoch [27/101], Step [10/12] Loss: 0.16631232500076293\n",
            "tp:654, tn: 2233, fp:0, fn: 63\n",
            "tp:605, tn: 2214, fp:3, fn: 115\n",
            "Train loss in epoch 27 is 0.17112047101060548 and Train HTER in epoch 27: 4.3933054393305415\n",
            "Dev loss in epoch 27 is 0.19697408253947893 and Dev HTER in epoch 27: 8.053770109757929\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [28/101], Step [5/12] Loss: 0.16420217752456664\n",
            "Epoch [28/101], Step [10/12] Loss: 0.16889852583408355\n",
            "tp:659, tn: 2232, fp:1, fn: 58\n",
            "tp:673, tn: 2216, fp:1, fn: 47\n",
            "Train loss in epoch 28 is 0.16281063357988992 and Train HTER in epoch 28: 4.067021806164783\n",
            "Dev loss in epoch 28 is 0.1807052157819271 and Dev HTER in epoch 28: 3.28644188843783\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [29/101], Step [5/12] Loss: 0.1595677077770233\n",
            "Epoch [29/101], Step [10/12] Loss: 0.15553126931190492\n",
            "tp:685, tn: 2230, fp:3, fn: 32\n",
            "tp:633, tn: 2213, fp:4, fn: 87\n",
            "Train loss in epoch 29 is 0.15927952031294504 and Train HTER in epoch 29: 2.298694428257264\n",
            "Dev loss in epoch 29 is 0.18497647593418756 and Dev HTER in epoch 29: 6.131878664862422\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [30/101], Step [5/12] Loss: 0.1564280152320862\n",
            "Epoch [30/101], Step [10/12] Loss: 0.14909223318099976\n",
            "tp:666, tn: 2233, fp:0, fn: 51\n",
            "tp:651, tn: 2215, fp:2, fn: 69\n",
            "Train loss in epoch 30 is 0.15366753563284874 and Train HTER in epoch 30: 3.556485355648542\n",
            "Dev loss in epoch 30 is 0.17261231069763502 and Dev HTER in epoch 30: 4.836772665764544\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [31/101], Step [5/12] Loss: 0.15636706948280335\n",
            "Epoch [31/101], Step [10/12] Loss: 0.1486538529396057\n",
            "tp:676, tn: 2228, fp:5, fn: 41\n",
            "tp:667, tn: 2214, fp:3, fn: 53\n",
            "Train loss in epoch 31 is 0.15109274412194887 and Train HTER in epoch 31: 2.9710922944222617\n",
            "Dev loss in epoch 31 is 0.1703164242208004 and Dev HTER in epoch 31: 3.748214554202378\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [32/101], Step [5/12] Loss: 0.14524616301059723\n",
            "Epoch [32/101], Step [10/12] Loss: 0.14351890087127686\n",
            "tp:706, tn: 2233, fp:0, fn: 11\n",
            "tp:690, tn: 2217, fp:0, fn: 30\n",
            "Train loss in epoch 32 is 0.13857483056684336 and Train HTER in epoch 32: 0.7670850767085069\n",
            "Dev loss in epoch 32 is 0.16019576415419579 and Dev HTER in epoch 32: 2.083333333333326\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [33/101], Step [5/12] Loss: 0.14036708176136017\n",
            "Epoch [33/101], Step [10/12] Loss: 0.14331928491592408\n",
            "tp:717, tn: 2227, fp:6, fn: 0\n",
            "tp:700, tn: 2215, fp:2, fn: 20\n",
            "Train loss in epoch 33 is 0.13416866337259611 and Train HTER in epoch 33: 0.13434841021047195\n",
            "Dev loss in epoch 33 is 0.15809808298945427 and Dev HTER in epoch 33: 1.433994887986767\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [34/101], Step [5/12] Loss: 0.13689830303192138\n",
            "Epoch [34/101], Step [10/12] Loss: 0.1486838072538376\n",
            "tp:708, tn: 2221, fp:12, fn: 9\n",
            "tp:680, tn: 2203, fp:14, fn: 40\n",
            "Train loss in epoch 34 is 0.14545923843979836 and Train HTER in epoch 34: 0.8963118831824657\n",
            "Dev loss in epoch 34 is 0.1694378281633059 and Dev HTER in epoch 34: 3.093519771462938\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [35/101], Step [5/12] Loss: 0.1438135802745819\n",
            "Epoch [35/101], Step [10/12] Loss: 0.14178870916366576\n",
            "tp:707, tn: 2233, fp:0, fn: 10\n",
            "tp:696, tn: 2217, fp:0, fn: 24\n",
            "Train loss in epoch 35 is 0.13224300369620323 and Train HTER in epoch 35: 0.6973500697350143\n",
            "Dev loss in epoch 35 is 0.15146484971046448 and Dev HTER in epoch 35: 1.6666666666666607\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [36/101], Step [5/12] Loss: 0.13034985661506654\n",
            "Epoch [36/101], Step [10/12] Loss: 0.14257168173789977\n",
            "tp:715, tn: 2226, fp:7, fn: 2\n",
            "tp:693, tn: 2206, fp:11, fn: 27\n",
            "Train loss in epoch 36 is 0.14248668402433395 and Train HTER in epoch 36: 0.2962098258592283\n",
            "Dev loss in epoch 36 is 0.1674841729303201 and Dev HTER in epoch 36: 2.123082995038339\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [37/101], Step [5/12] Loss: 0.13737497478723526\n",
            "Epoch [37/101], Step [10/12] Loss: 0.13872629404067993\n",
            "tp:693, tn: 2230, fp:3, fn: 24\n",
            "tp:639, tn: 2214, fp:3, fn: 81\n",
            "Train loss in epoch 37 is 0.1531641185283661 and Train HTER in epoch 37: 1.740814372469257\n",
            "Dev loss in epoch 37 is 0.17433447390794754 and Dev HTER in epoch 37: 5.692658998646816\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [38/101], Step [5/12] Loss: 0.14944368600845337\n",
            "Epoch [38/101], Step [10/12] Loss: 0.14953758120536803\n",
            "tp:701, tn: 2225, fp:8, fn: 16\n",
            "tp:663, tn: 2205, fp:12, fn: 57\n",
            "Train loss in epoch 38 is 0.1446415620545546 and Train HTER in epoch 38: 1.294891325189984\n",
            "Dev loss in epoch 38 is 0.1650532161196073 and Dev HTER in epoch 38: 4.228969327920618\n",
            "Epoch    38: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [39/101], Step [5/12] Loss: 0.14586201608181\n",
            "Epoch [39/101], Step [10/12] Loss: 0.13112993836402892\n",
            "tp:709, tn: 2230, fp:3, fn: 8\n",
            "tp:703, tn: 2215, fp:2, fn: 17\n",
            "Train loss in epoch 39 is 0.13180427191158137 and Train HTER in epoch 39: 0.6250542608932541\n",
            "Dev loss in epoch 39 is 0.1489799196521441 and Dev HTER in epoch 39: 1.2256615546534344\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [40/101], Step [5/12] Loss: 0.12752916365861894\n",
            "Epoch [40/101], Step [10/12] Loss: 0.12807051241397857\n",
            "tp:711, tn: 2230, fp:3, fn: 6\n",
            "tp:691, tn: 2215, fp:2, fn: 29\n",
            "Train loss in epoch 40 is 0.12426240059236686 and Train HTER in epoch 40: 0.4855842469462468\n",
            "Dev loss in epoch 40 is 0.14876592407623926 and Dev HTER in epoch 40: 2.0589948879867648\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [41/101], Step [5/12] Loss: 0.1256175771355629\n",
            "Epoch [41/101], Step [10/12] Loss: 0.1224134013056755\n",
            "tp:717, tn: 2231, fp:2, fn: 0\n",
            "tp:707, tn: 2214, fp:3, fn: 13\n",
            "Train loss in epoch 41 is 0.1219273420671622 and Train HTER in epoch 41: 0.04478280340349805\n",
            "Dev loss in epoch 41 is 0.14735276127854982 and Dev HTER in epoch 41: 0.9704367764245991\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [42/101], Step [5/12] Loss: 0.1194322720170021\n",
            "Epoch [42/101], Step [10/12] Loss: 0.12255861908197403\n",
            "tp:716, tn: 2231, fp:2, fn: 1\n",
            "tp:708, tn: 2216, fp:1, fn: 12\n",
            "Train loss in epoch 42 is 0.1216848623007536 and Train HTER in epoch 42: 0.1145178103769906\n",
            "Dev loss in epoch 42 is 0.14519695565104485 and Dev HTER in epoch 42: 0.8558863328822719\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [43/101], Step [5/12] Loss: 0.11816179603338242\n",
            "Epoch [43/101], Step [10/12] Loss: 0.12129787355661392\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:699, tn: 2214, fp:3, fn: 21\n",
            "Train loss in epoch 43 is 0.11935670611759026 and Train HTER in epoch 43: 0.0\n",
            "Dev loss in epoch 43 is 0.14643709982434908 and Dev HTER in epoch 43: 1.5259923319801527\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [44/101], Step [5/12] Loss: 0.11831163167953491\n",
            "Epoch [44/101], Step [10/12] Loss: 0.12344440072774887\n",
            "tp:716, tn: 2232, fp:1, fn: 1\n",
            "tp:699, tn: 2215, fp:2, fn: 21\n",
            "Train loss in epoch 44 is 0.12090681307017803 and Train HTER in epoch 44: 0.09212640867524158\n",
            "Dev loss in epoch 44 is 0.14527477199832597 and Dev HTER in epoch 44: 1.5034393324312112\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [45/101], Step [5/12] Loss: 0.11940910071134567\n",
            "Epoch [45/101], Step [10/12] Loss: 0.12257245928049088\n",
            "tp:717, tn: 2231, fp:2, fn: 0\n",
            "tp:708, tn: 2216, fp:1, fn: 12\n",
            "Train loss in epoch 45 is 0.11881513769427936 and Train HTER in epoch 45: 0.04478280340349805\n",
            "Dev loss in epoch 45 is 0.14158466085791588 and Dev HTER in epoch 45: 0.8558863328822719\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [46/101], Step [5/12] Loss: 0.12111989855766296\n",
            "Epoch [46/101], Step [10/12] Loss: 0.12050736099481582\n",
            "tp:717, tn: 2231, fp:2, fn: 0\n",
            "tp:701, tn: 2214, fp:3, fn: 19\n",
            "Train loss in epoch 46 is 0.11932635928193729 and Train HTER in epoch 46: 0.04478280340349805\n",
            "Dev loss in epoch 46 is 0.14382318034768105 and Dev HTER in epoch 46: 1.3871034430912643\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [47/101], Step [5/12] Loss: 0.11796479821205139\n",
            "Epoch [47/101], Step [10/12] Loss: 0.1186738669872284\n",
            "tp:717, tn: 2231, fp:2, fn: 0\n",
            "tp:702, tn: 2217, fp:0, fn: 18\n",
            "Train loss in epoch 47 is 0.11861390868822734 and Train HTER in epoch 47: 0.04478280340349805\n",
            "Dev loss in epoch 47 is 0.14307889342308044 and Dev HTER in epoch 47: 1.2499999999999956\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [48/101], Step [5/12] Loss: 0.11621719002723693\n",
            "Epoch [48/101], Step [10/12] Loss: 0.11994851678609848\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:705, tn: 2217, fp:0, fn: 15\n",
            "Train loss in epoch 48 is 0.11510316468775272 and Train HTER in epoch 48: 0.0\n",
            "Dev loss in epoch 48 is 0.14210792382558188 and Dev HTER in epoch 48: 1.041666666666674\n",
            "Epoch    48: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [49/101], Step [5/12] Loss: 0.11543728709220887\n",
            "Epoch [49/101], Step [10/12] Loss: 0.11511918753385544\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:708, tn: 2217, fp:0, fn: 12\n",
            "Train loss in epoch 49 is 0.11767279418806235 and Train HTER in epoch 49: 0.0\n",
            "Dev loss in epoch 49 is 0.13984018564224243 and Dev HTER in epoch 49: 0.8333333333333304\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [50/101], Step [5/12] Loss: 0.11639844477176667\n",
            "Epoch [50/101], Step [10/12] Loss: 0.11664553731679916\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:701, tn: 2216, fp:1, fn: 19\n",
            "Train loss in epoch 50 is 0.11491112535198529 and Train HTER in epoch 50: 0.0\n",
            "Dev loss in epoch 50 is 0.14167933414379755 and Dev HTER in epoch 50: 1.3419974439933924\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [51/101], Step [5/12] Loss: 0.11437882632017135\n",
            "Epoch [51/101], Step [10/12] Loss: 0.11695299744606018\n",
            "tp:715, tn: 2233, fp:0, fn: 2\n",
            "tp:706, tn: 2214, fp:3, fn: 14\n",
            "Train loss in epoch 51 is 0.11430091472963493 and Train HTER in epoch 51: 0.1394700139470073\n",
            "Dev loss in epoch 51 is 0.1397772996375958 and Dev HTER in epoch 51: 1.0398812208690433\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [52/101], Step [5/12] Loss: 0.11917653828859329\n",
            "Epoch [52/101], Step [10/12] Loss: 0.11349248439073563\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:702, tn: 2217, fp:0, fn: 18\n",
            "Train loss in epoch 52 is 0.11550231277942657 and Train HTER in epoch 52: 0.0\n",
            "Dev loss in epoch 52 is 0.14090294390916824 and Dev HTER in epoch 52: 1.2499999999999956\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [53/101], Step [5/12] Loss: 0.1120464637875557\n",
            "Epoch [53/101], Step [10/12] Loss: 0.11877580136060714\n",
            "tp:716, tn: 2233, fp:0, fn: 1\n",
            "tp:701, tn: 2217, fp:0, fn: 19\n",
            "Train loss in epoch 53 is 0.11580498144030571 and Train HTER in epoch 53: 0.06973500697349255\n",
            "Dev loss in epoch 53 is 0.14034337426225343 and Dev HTER in epoch 53: 1.3194444444444509\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [54/101], Step [5/12] Loss: 0.11426306217908859\n",
            "Epoch [54/101], Step [10/12] Loss: 0.11675545126199723\n",
            "tp:717, tn: 2232, fp:1, fn: 0\n",
            "tp:699, tn: 2215, fp:2, fn: 21\n",
            "Train loss in epoch 54 is 0.11601827666163445 and Train HTER in epoch 54: 0.022391401701749025\n",
            "Dev loss in epoch 54 is 0.14172126601139703 and Dev HTER in epoch 54: 1.5034393324312112\n",
            "Epoch    54: reducing learning rate of group 0 to 1.0000e-07.\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [55/101], Step [5/12] Loss: 0.11063152849674225\n",
            "Epoch [55/101], Step [10/12] Loss: 0.11693050563335419\n",
            "tp:717, tn: 2232, fp:1, fn: 0\n",
            "tp:704, tn: 2217, fp:0, fn: 16\n",
            "Train loss in epoch 55 is 0.11486339569091797 and Train HTER in epoch 55: 0.022391401701749025\n",
            "Dev loss in epoch 55 is 0.14045429478089014 and Dev HTER in epoch 55: 1.1111111111111072\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [56/101], Step [5/12] Loss: 0.11739628165960311\n",
            "Epoch [56/101], Step [10/12] Loss: 0.11306905299425125\n",
            "tp:717, tn: 2232, fp:1, fn: 0\n",
            "tp:702, tn: 2217, fp:0, fn: 18\n",
            "Train loss in epoch 56 is 0.11570581917961438 and Train HTER in epoch 56: 0.022391401701749025\n",
            "Dev loss in epoch 56 is 0.14180068547526994 and Dev HTER in epoch 56: 1.2499999999999956\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [57/101], Step [5/12] Loss: 0.11538749784231186\n",
            "Epoch [57/101], Step [10/12] Loss: 0.1145701214671135\n",
            "tp:716, tn: 2233, fp:0, fn: 1\n",
            "tp:705, tn: 2216, fp:1, fn: 15\n",
            "Train loss in epoch 57 is 0.11525816470384598 and Train HTER in epoch 57: 0.06973500697349255\n",
            "Dev loss in epoch 57 is 0.13980753098924956 and Dev HTER in epoch 57: 1.0642196662156156\n",
            "Epoch    57: reducing learning rate of group 0 to 1.0000e-08.\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [58/101], Step [5/12] Loss: 0.11370117664337158\n",
            "Epoch [58/101], Step [10/12] Loss: 0.11681801676750184\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:707, tn: 2216, fp:1, fn: 13\n",
            "Train loss in epoch 58 is 0.11626201681792736 and Train HTER in epoch 58: 0.0\n",
            "Dev loss in epoch 58 is 0.1403591906030973 and Dev HTER in epoch 58: 0.9253307773267272\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [59/101], Step [5/12] Loss: 0.11490944623947144\n",
            "Epoch [59/101], Step [10/12] Loss: 0.11500171571969986\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:708, tn: 2216, fp:1, fn: 12\n",
            "Train loss in epoch 59 is 0.11551900083820026 and Train HTER in epoch 59: 0.0\n",
            "Dev loss in epoch 59 is 0.13955812404553095 and Dev HTER in epoch 59: 0.8558863328822719\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [60/101], Step [5/12] Loss: 0.11556087285280228\n",
            "Epoch [60/101], Step [10/12] Loss: 0.11772223860025406\n",
            "tp:717, tn: 2232, fp:1, fn: 0\n",
            "tp:701, tn: 2217, fp:0, fn: 19\n",
            "Train loss in epoch 60 is 0.11518886064489682 and Train HTER in epoch 60: 0.022391401701749025\n",
            "Dev loss in epoch 60 is 0.13944928844769797 and Dev HTER in epoch 60: 1.3194444444444509\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [61/101], Step [5/12] Loss: 0.11606591343879699\n",
            "Epoch [61/101], Step [10/12] Loss: 0.11556688100099563\n",
            "tp:717, tn: 2232, fp:1, fn: 0\n",
            "tp:700, tn: 2215, fp:2, fn: 20\n",
            "Train loss in epoch 61 is 0.11506501585245132 and Train HTER in epoch 61: 0.022391401701749025\n",
            "Dev loss in epoch 61 is 0.1421423740684986 and Dev HTER in epoch 61: 1.433994887986767\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [62/101], Step [5/12] Loss: 0.11611330211162567\n",
            "Epoch [62/101], Step [10/12] Loss: 0.1149926707148552\n",
            "tp:717, tn: 2232, fp:1, fn: 0\n",
            "tp:696, tn: 2215, fp:2, fn: 24\n",
            "Train loss in epoch 62 is 0.11562610790133476 and Train HTER in epoch 62: 0.022391401701749025\n",
            "Dev loss in epoch 62 is 0.1423189751803875 and Dev HTER in epoch 62: 1.7117726657645438\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [63/101], Step [5/12] Loss: 0.11608764082193375\n",
            "Epoch [63/101], Step [10/12] Loss: 0.11856146454811096\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:704, tn: 2217, fp:0, fn: 16\n",
            "Train loss in epoch 63 is 0.11519006080925465 and Train HTER in epoch 63: 0.0\n",
            "Dev loss in epoch 63 is 0.14198589573303858 and Dev HTER in epoch 63: 1.1111111111111072\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [64/101], Step [5/12] Loss: 0.11541662812232971\n",
            "Epoch [64/101], Step [10/12] Loss: 0.11686562597751618\n",
            "tp:716, tn: 2232, fp:1, fn: 1\n",
            "tp:710, tn: 2217, fp:0, fn: 10\n",
            "Train loss in epoch 64 is 0.11606978438794613 and Train HTER in epoch 64: 0.09212640867524158\n",
            "Dev loss in epoch 64 is 0.1401983325680097 and Dev HTER in epoch 64: 0.694444444444442\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [65/101], Step [5/12] Loss: 0.11579811573028564\n",
            "Epoch [65/101], Step [10/12] Loss: 0.11643127351999283\n",
            "tp:716, tn: 2233, fp:0, fn: 1\n",
            "tp:704, tn: 2215, fp:2, fn: 16\n",
            "Train loss in epoch 65 is 0.11554360017180443 and Train HTER in epoch 65: 0.06973500697349255\n",
            "Dev loss in epoch 65 is 0.14230539401372275 and Dev HTER in epoch 65: 1.1562171102089902\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [66/101], Step [5/12] Loss: 0.11770561933517457\n",
            "Epoch [66/101], Step [10/12] Loss: 0.11462750434875488\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:704, tn: 2216, fp:1, fn: 16\n",
            "Train loss in epoch 66 is 0.11467359401285648 and Train HTER in epoch 66: 0.0\n",
            "Dev loss in epoch 66 is 0.13978307197491327 and Dev HTER in epoch 66: 1.1336641106600487\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [67/101], Step [5/12] Loss: 0.11619907766580581\n",
            "Epoch [67/101], Step [10/12] Loss: 0.11504263579845428\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:700, tn: 2216, fp:1, fn: 20\n",
            "Train loss in epoch 67 is 0.11446505909164746 and Train HTER in epoch 67: 0.0\n",
            "Dev loss in epoch 67 is 0.1414521945019563 and Dev HTER in epoch 67: 1.4114418884378255\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [68/101], Step [5/12] Loss: 0.11254204660654069\n",
            "Epoch [68/101], Step [10/12] Loss: 0.11454544514417649\n",
            "tp:717, tn: 2232, fp:1, fn: 0\n",
            "tp:706, tn: 2215, fp:2, fn: 14\n",
            "Train loss in epoch 68 is 0.11692105047404766 and Train HTER in epoch 68: 0.022391401701749025\n",
            "Dev loss in epoch 68 is 0.1406108203033606 and Dev HTER in epoch 68: 1.0173282213201018\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [69/101], Step [5/12] Loss: 0.11405599117279053\n",
            "Epoch [69/101], Step [10/12] Loss: 0.11933076828718185\n",
            "tp:716, tn: 2233, fp:0, fn: 1\n",
            "tp:714, tn: 2216, fp:1, fn: 6\n",
            "Train loss in epoch 69 is 0.11773525799314181 and Train HTER in epoch 69: 0.06973500697349255\n",
            "Dev loss in epoch 69 is 0.1392209753394127 and Dev HTER in epoch 69: 0.4392196662156067\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [70/101], Step [5/12] Loss: 0.11456563621759415\n",
            "Epoch [70/101], Step [10/12] Loss: 0.11636587530374527\n",
            "tp:716, tn: 2232, fp:1, fn: 1\n",
            "tp:708, tn: 2216, fp:1, fn: 12\n",
            "Train loss in epoch 70 is 0.11501442454755306 and Train HTER in epoch 70: 0.09212640867524158\n",
            "Dev loss in epoch 70 is 0.13960441450277963 and Dev HTER in epoch 70: 0.8558863328822719\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [71/101], Step [5/12] Loss: 0.11433669030666352\n",
            "Epoch [71/101], Step [10/12] Loss: 0.1150139570236206\n",
            "tp:716, tn: 2232, fp:1, fn: 1\n",
            "tp:706, tn: 2215, fp:2, fn: 14\n",
            "Train loss in epoch 71 is 0.116215068846941 and Train HTER in epoch 71: 0.09212640867524158\n",
            "Dev loss in epoch 71 is 0.14112897341450056 and Dev HTER in epoch 71: 1.0173282213201018\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [72/101], Step [5/12] Loss: 0.11576980799436569\n",
            "Epoch [72/101], Step [10/12] Loss: 0.112717305123806\n",
            "tp:716, tn: 2233, fp:0, fn: 1\n",
            "tp:714, tn: 2216, fp:1, fn: 6\n",
            "Train loss in epoch 72 is 0.11589790942768256 and Train HTER in epoch 72: 0.06973500697349255\n",
            "Dev loss in epoch 72 is 0.1410417395333449 and Dev HTER in epoch 72: 0.4392196662156067\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [73/101], Step [5/12] Loss: 0.11573767215013504\n",
            "Epoch [73/101], Step [10/12] Loss: 0.11594324111938477\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:713, tn: 2216, fp:1, fn: 7\n",
            "Train loss in epoch 73 is 0.1145520539333423 and Train HTER in epoch 73: 0.0\n",
            "Dev loss in epoch 73 is 0.14103688796361288 and Dev HTER in epoch 73: 0.5086641106600509\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [74/101], Step [5/12] Loss: 0.11391377300024033\n",
            "Epoch [74/101], Step [10/12] Loss: 0.11785407960414887\n",
            "tp:713, tn: 2232, fp:1, fn: 4\n",
            "tp:698, tn: 2215, fp:2, fn: 22\n",
            "Train loss in epoch 74 is 0.11520998800794284 and Train HTER in epoch 74: 0.30133142959575254\n",
            "Dev loss in epoch 74 is 0.14292418584227562 and Dev HTER in epoch 74: 1.5728837768756554\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [75/101], Step [5/12] Loss: 0.116419517993927\n",
            "Epoch [75/101], Step [10/12] Loss: 0.11479371786117554\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:700, tn: 2216, fp:1, fn: 20\n",
            "Train loss in epoch 75 is 0.11669874439636867 and Train HTER in epoch 75: 0.0\n",
            "Dev loss in epoch 75 is 0.14068907871842384 and Dev HTER in epoch 75: 1.4114418884378255\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [76/101], Step [5/12] Loss: 0.11760242581367493\n",
            "Epoch [76/101], Step [10/12] Loss: 0.11541523784399033\n",
            "tp:717, tn: 2232, fp:1, fn: 0\n",
            "tp:709, tn: 2216, fp:1, fn: 11\n",
            "Train loss in epoch 76 is 0.11627422956128915 and Train HTER in epoch 76: 0.022391401701749025\n",
            "Dev loss in epoch 76 is 0.141020600994428 and Dev HTER in epoch 76: 0.7864418884378277\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [77/101], Step [5/12] Loss: 0.11645088046789169\n",
            "Epoch [77/101], Step [10/12] Loss: 0.11612584739923477\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:703, tn: 2217, fp:0, fn: 17\n",
            "Train loss in epoch 77 is 0.1140007929255565 and Train HTER in epoch 77: 0.0\n",
            "Dev loss in epoch 77 is 0.14098054667313895 and Dev HTER in epoch 77: 1.1805555555555625\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [78/101], Step [5/12] Loss: 0.11895279586315155\n",
            "Epoch [78/101], Step [10/12] Loss: 0.11654766052961349\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:707, tn: 2217, fp:0, fn: 13\n",
            "Train loss in epoch 78 is 0.11641738998393218 and Train HTER in epoch 78: 0.0\n",
            "Dev loss in epoch 78 is 0.14053433140118918 and Dev HTER in epoch 78: 0.9027777777777857\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [79/101], Step [5/12] Loss: 0.11573682576417924\n",
            "Epoch [79/101], Step [10/12] Loss: 0.11532081365585327\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:703, tn: 2217, fp:0, fn: 17\n",
            "Train loss in epoch 79 is 0.11534819006919861 and Train HTER in epoch 79: 0.0\n",
            "Dev loss in epoch 79 is 0.1403097721437613 and Dev HTER in epoch 79: 1.1805555555555625\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [80/101], Step [5/12] Loss: 0.11596880108118057\n",
            "Epoch [80/101], Step [10/12] Loss: 0.11072407811880111\n",
            "tp:717, tn: 2232, fp:1, fn: 0\n",
            "tp:701, tn: 2217, fp:0, fn: 19\n",
            "Train loss in epoch 80 is 0.1153525256862243 and Train HTER in epoch 80: 0.022391401701749025\n",
            "Dev loss in epoch 80 is 0.1405139739314715 and Dev HTER in epoch 80: 1.3194444444444509\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [81/101], Step [5/12] Loss: 0.11536761820316314\n",
            "Epoch [81/101], Step [10/12] Loss: 0.11666048169136048\n",
            "tp:716, tn: 2232, fp:1, fn: 1\n",
            "tp:690, tn: 2217, fp:0, fn: 30\n",
            "Train loss in epoch 81 is 0.11680726272364457 and Train HTER in epoch 81: 0.09212640867524158\n",
            "Dev loss in epoch 81 is 0.14293979729215303 and Dev HTER in epoch 81: 2.083333333333326\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [82/101], Step [5/12] Loss: 0.11408143043518067\n",
            "Epoch [82/101], Step [10/12] Loss: 0.11370594948530197\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:704, tn: 2217, fp:0, fn: 16\n",
            "Train loss in epoch 82 is 0.1136086955666542 and Train HTER in epoch 82: 0.0\n",
            "Dev loss in epoch 82 is 0.141273216654857 and Dev HTER in epoch 82: 1.1111111111111072\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [83/101], Step [5/12] Loss: 0.11439595073461532\n",
            "Epoch [83/101], Step [10/12] Loss: 0.11525269895792008\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:709, tn: 2216, fp:1, fn: 11\n",
            "Train loss in epoch 83 is 0.11477757804095745 and Train HTER in epoch 83: 0.0\n",
            "Dev loss in epoch 83 is 0.14087280010183653 and Dev HTER in epoch 83: 0.7864418884378277\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [84/101], Step [5/12] Loss: 0.11645108461380005\n",
            "Epoch [84/101], Step [10/12] Loss: 0.11726520508527756\n",
            "tp:716, tn: 2232, fp:1, fn: 1\n",
            "tp:708, tn: 2217, fp:0, fn: 12\n",
            "Train loss in epoch 84 is 0.11861711243788402 and Train HTER in epoch 84: 0.09212640867524158\n",
            "Dev loss in epoch 84 is 0.1404224062959353 and Dev HTER in epoch 84: 0.8333333333333304\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [85/101], Step [5/12] Loss: 0.11731379479169846\n",
            "Epoch [85/101], Step [10/12] Loss: 0.11400876045227051\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:705, tn: 2217, fp:0, fn: 15\n",
            "Train loss in epoch 85 is 0.11576316691935062 and Train HTER in epoch 85: 0.0\n",
            "Dev loss in epoch 85 is 0.14026726658145586 and Dev HTER in epoch 85: 1.041666666666674\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [86/101], Step [5/12] Loss: 0.11715657711029052\n",
            "Epoch [86/101], Step [10/12] Loss: 0.11282818615436555\n",
            "tp:717, tn: 2231, fp:2, fn: 0\n",
            "tp:702, tn: 2215, fp:2, fn: 18\n",
            "Train loss in epoch 86 is 0.11522382249434789 and Train HTER in epoch 86: 0.04478280340349805\n",
            "Dev loss in epoch 86 is 0.14224611719449362 and Dev HTER in epoch 86: 1.2951059990978786\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [87/101], Step [5/12] Loss: 0.11252615600824356\n",
            "Epoch [87/101], Step [10/12] Loss: 0.11809615641832352\n",
            "tp:717, tn: 2232, fp:1, fn: 0\n",
            "tp:708, tn: 2217, fp:0, fn: 12\n",
            "Train loss in epoch 87 is 0.11550810933113098 and Train HTER in epoch 87: 0.022391401701749025\n",
            "Dev loss in epoch 87 is 0.14165848617752394 and Dev HTER in epoch 87: 0.8333333333333304\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [88/101], Step [5/12] Loss: 0.11342601031064987\n",
            "Epoch [88/101], Step [10/12] Loss: 0.11677813977003097\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:705, tn: 2217, fp:0, fn: 15\n",
            "Train loss in epoch 88 is 0.11589642365773518 and Train HTER in epoch 88: 0.0\n",
            "Dev loss in epoch 88 is 0.14184682567914328 and Dev HTER in epoch 88: 1.041666666666674\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [89/101], Step [5/12] Loss: 0.1152146503329277\n",
            "Epoch [89/101], Step [10/12] Loss: 0.11557994484901428\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:708, tn: 2217, fp:0, fn: 12\n",
            "Train loss in epoch 89 is 0.11504080332815647 and Train HTER in epoch 89: 0.0\n",
            "Dev loss in epoch 89 is 0.13947622602184614 and Dev HTER in epoch 89: 0.8333333333333304\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [90/101], Step [5/12] Loss: 0.11432974636554719\n",
            "Epoch [90/101], Step [10/12] Loss: 0.1176095500588417\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:708, tn: 2216, fp:1, fn: 12\n",
            "Train loss in epoch 90 is 0.11593733665843804 and Train HTER in epoch 90: 0.0\n",
            "Dev loss in epoch 90 is 0.14072610313693681 and Dev HTER in epoch 90: 0.8558863328822719\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [91/101], Step [5/12] Loss: 0.118791463971138\n",
            "Epoch [91/101], Step [10/12] Loss: 0.11426916718482971\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:708, tn: 2216, fp:1, fn: 12\n",
            "Train loss in epoch 91 is 0.11470942075053851 and Train HTER in epoch 91: 0.0\n",
            "Dev loss in epoch 91 is 0.1385022128621737 and Dev HTER in epoch 91: 0.8558863328822719\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [92/101], Step [5/12] Loss: 0.11602178364992141\n",
            "Epoch [92/101], Step [10/12] Loss: 0.1140005424618721\n",
            "tp:714, tn: 2232, fp:1, fn: 3\n",
            "tp:709, tn: 2217, fp:0, fn: 11\n",
            "Train loss in epoch 92 is 0.1174104493111372 and Train HTER in epoch 92: 0.2315964226222489\n",
            "Dev loss in epoch 92 is 0.14050138369202614 and Dev HTER in epoch 92: 0.7638888888888862\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [93/101], Step [5/12] Loss: 0.11332915425300598\n",
            "Epoch [93/101], Step [10/12] Loss: 0.1184805080294609\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:704, tn: 2216, fp:1, fn: 16\n",
            "Train loss in epoch 93 is 0.11497912742197514 and Train HTER in epoch 93: 0.0\n",
            "Dev loss in epoch 93 is 0.1397129769126574 and Dev HTER in epoch 93: 1.1336641106600487\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [94/101], Step [5/12] Loss: 0.11516401916742325\n",
            "Epoch [94/101], Step [10/12] Loss: 0.11716480255126953\n",
            "tp:712, tn: 2232, fp:1, fn: 5\n",
            "tp:708, tn: 2215, fp:2, fn: 12\n",
            "Train loss in epoch 94 is 0.11860080001254876 and Train HTER in epoch 94: 0.3710664365692562\n",
            "Dev loss in epoch 94 is 0.14112573737899461 and Dev HTER in epoch 94: 0.8784393324312134\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [95/101], Step [5/12] Loss: 0.11344632655382156\n",
            "Epoch [95/101], Step [10/12] Loss: 0.11835442036390305\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:704, tn: 2217, fp:0, fn: 16\n",
            "Train loss in epoch 95 is 0.1168700580795606 and Train HTER in epoch 95: 0.0\n",
            "Dev loss in epoch 95 is 0.1414743730177482 and Dev HTER in epoch 95: 1.1111111111111072\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [96/101], Step [5/12] Loss: 0.1167413741350174\n",
            "Epoch [96/101], Step [10/12] Loss: 0.11440936625003814\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:710, tn: 2217, fp:0, fn: 10\n",
            "Train loss in epoch 96 is 0.11510975969334443 and Train HTER in epoch 96: 0.0\n",
            "Dev loss in epoch 96 is 0.13954302171866098 and Dev HTER in epoch 96: 0.694444444444442\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [97/101], Step [5/12] Loss: 0.11599262356758118\n",
            "Epoch [97/101], Step [10/12] Loss: 0.11532707512378693\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:702, tn: 2217, fp:0, fn: 18\n",
            "Train loss in epoch 97 is 0.11497317502895991 and Train HTER in epoch 97: 0.0\n",
            "Dev loss in epoch 97 is 0.14068631827831268 and Dev HTER in epoch 97: 1.2499999999999956\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [98/101], Step [5/12] Loss: 0.11333123445510865\n",
            "Epoch [98/101], Step [10/12] Loss: 0.11556316614151001\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:711, tn: 2217, fp:0, fn: 9\n",
            "Train loss in epoch 98 is 0.11454516400893529 and Train HTER in epoch 98: 0.0\n",
            "Dev loss in epoch 98 is 0.1411927007138729 and Dev HTER in epoch 98: 0.6249999999999978\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [99/101], Step [5/12] Loss: 0.11327011734247208\n",
            "Epoch [99/101], Step [10/12] Loss: 0.11580914109945298\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:710, tn: 2215, fp:2, fn: 10\n",
            "Train loss in epoch 99 is 0.11631514007846515 and Train HTER in epoch 99: 0.0\n",
            "Dev loss in epoch 99 is 0.1398964338004589 and Dev HTER in epoch 99: 0.739550443542325\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [100/101], Step [5/12] Loss: 0.11466121673583984\n",
            "Epoch [100/101], Step [10/12] Loss: 0.11632018983364105\n",
            "tp:717, tn: 2233, fp:0, fn: 0\n",
            "tp:709, tn: 2217, fp:0, fn: 11\n",
            "Train loss in epoch 100 is 0.11667675462861855 and Train HTER in epoch 100: 0.0\n",
            "Dev loss in epoch 100 is 0.14136264100670815 and Dev HTER in epoch 100: 0.7638888888888862\n",
            "Model saved successfully!\n",
            "\n",
            "Epoch [101/101], Step [5/12] Loss: 0.11528783589601517\n",
            "Epoch [101/101], Step [10/12] Loss: 0.11589278280735016\n",
            "tp:716, tn: 2233, fp:0, fn: 1\n",
            "tp:704, tn: 2216, fp:1, fn: 16\n",
            "Train loss in epoch 101 is 0.11585445888340473 and Train HTER in epoch 101: 0.06973500697349255\n",
            "Dev loss in epoch 101 is 0.1407277894516786 and Dev HTER in epoch 101: 1.1336641106600487\n",
            "Model saved successfully!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq9NFykmqEVY",
        "colab_type": "text"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUICC7rp61k-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "68f6954a-1a28-4709-e0fa-0deb5740c2a0"
      },
      "source": [
        "criterion=nn.CrossEntropyLoss(reduction='mean') # loss criterion\n",
        "resnet=torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=False)\n",
        "model= Resnet(resnet )\n",
        "print(model)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Resnet(\n",
            "  (cnn): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (5): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (6): Flatten()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (1): Dropout(p=0.5, inplace=False)\n",
            "    (2): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru_QpdYE68MJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4acd469e-0a11-44d6-f2b7-575a19759c0a"
      },
      "source": [
        "model.load_state_dict(torch.load(\"/content/gdrive/My Drive/Machine Learning/Face Anti-spoofing/Codes/Replay Attack/weights_replay_attack_1FPS/No LBP HTER 0.04, lr= 0.001, weight decay = 1.5, batch size =256, best hter = 0.04 epoch 38/Resnet_Replay_attack_No_LBP_38_0.0.pkl\"))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l346drOMqaGP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0f4d7e73-ec6e-480f-b95e-68a89e5699d2"
      },
      "source": [
        "test_loader=DataLoader(test_dataset, batch_size=256, shuffle=True, num_workers=8) \n",
        "len_test_dataset= len(test_dataset)\n",
        "\n",
        "print(f\"Total number of elements in test dataset: {len_test_dataset}\")"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of elements in test dataset: 3888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZEbQ9F8qdbm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "cd596b5a-62e0-4536-a1a5-881e0f157b7c"
      },
      "source": [
        "model=model.to(device)\n",
        "with torch.no_grad():      \n",
        "      test_hter, test_loss=HTER(model=model, loss_criterion=criterion, loader=test_loader)\n",
        "      print(f\"Test loss  is {test_loss}\")\n",
        "      print(f'Test HTER: {test_hter}\\n')"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tp:937, tn: 2934, fp:4, fn: 13\n",
            "Test loss  is 0.143231850117445\n",
            "Test HTER: 0.7522840457167446\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}